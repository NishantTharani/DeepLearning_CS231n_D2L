{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_iter, test_iter, num_epochs, lr, optimizer=None, device=d2l.try_gpu()):\n",
    "    \"\"\"\n",
    "    Trains a network 'net'. Assumes that net.init_weights exists\n",
    "    \"\"\"\n",
    "    # 1: initialise weights\n",
    "#     net.apply(net.init_weights)\n",
    "    def init_weights_test(m):\n",
    "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "    net.apply(init_weights_test)\n",
    "\n",
    "    # 2: move model to device for training\n",
    "    net.to(device)\n",
    "    \n",
    "    # 3: set up optimizer, loss function, and animation stuff\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "#     optimizer = torch.optim.Adam(params=net.parameters(), lr=lr)\n",
    "    if optimizer is None:\n",
    "        optimizer = torch.optim.SGD(params=net.parameters(), lr=lr)\n",
    "    animator = d2l.Animator(xlabel=\"epoch number\", xlim=[0, num_epochs], legend=[\"train loss\", \"train acc\", \"test acc\"])\n",
    "    \n",
    "    # 4: training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        metric = d2l.Accumulator(3)\n",
    "        for i, (X, y) in enumerate(train_iter):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            net.train()\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            # temporarily disable grad to calculate metrics\n",
    "            with torch.no_grad():\n",
    "                train_loss = l\n",
    "#                 import ipdb; ipdb.set_trace()\n",
    "                _, preds = torch.max(y_hat, 1)\n",
    "                train_acc = ((preds == y).sum()) / float(X.shape[0])\n",
    "            if (i + 1) % 50 == 0:\n",
    "                animator.add(epoch + (i / len(train_iter)), (train_loss, train_acc, None))\n",
    "        test_acc = evaluate_accuracy_gpu(net, test_iter, device)\n",
    "        animator.add(epoch + 1, (None, None, test_acc))\n",
    "    \n",
    "    print(f'loss {train_loss:.3f}, train acc {train_acc:.3f}, test acc {test_acc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_loss(net, data_iter, device, loss=nn.CrossEntropyLoss()):\n",
    "    net.eval()\n",
    "    total_loss = 0\n",
    "    for i, (X, y) in enumerate(data_iter):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        total_loss += loss(net(X), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy_gpu(net, data_iter, device):\n",
    "    \"\"\"\n",
    "    Evaluate the accuracy of the model given by 'net' on \n",
    "    the DataLoader given by 'data_iter' using the device 'device'\n",
    "    \"\"\"\n",
    "    net.eval()\n",
    "    num_correct, num_total = 0, 0\n",
    "    for i, (X, y) in enumerate(data_iter):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        _, predicted = torch.max(net(X), 1)\n",
    "        correct = (predicted == y).sum()\n",
    "        num_correct += correct\n",
    "        num_total += y.shape[0]\n",
    "    return float(num_correct) / num_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fashion_mnist_iters(batch_size=128, resize=224):\n",
    "    transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize((resize, resize)),\n",
    "        torchvision.transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    all_set = torchvision.datasets.FashionMNIST(\"./data\", transform=transform, download=True)\n",
    "    test_set = torchvision.datasets.FashionMNIST(\"./data\", transform=transform, download=True, train=False)\n",
    "\n",
    "    # Build a validation set with an 80-20 split\n",
    "    val_idx = int(0.8 * len(all_set))\n",
    "\n",
    "    train_set, val_set = torch.utils.data.random_split(all_set, [val_idx, len(all_set) - val_idx])\n",
    "\n",
    "    all_iter = torch.utils.data.DataLoader(all_set, batch_size=batch_size, shuffle=True)\n",
    "    train_iter = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    val_iter = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=True)\n",
    "    test_iter = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=True)\n",
    "    return (all_iter, train_iter, val_iter, test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_size(size):\n",
    "\t\"\"\"Pretty prints a torch.Size object\"\"\"\n",
    "\tassert(isinstance(size, torch.Size))\n",
    "\treturn \" × \".join(map(str, size))\n",
    "\n",
    "def dump_tensors(gpu_only=True):\n",
    "\t\"\"\"Prints a list of the Tensors being tracked by the garbage collector.\"\"\"\n",
    "\timport gc\n",
    "\ttotal_size = 0\n",
    "\tfor obj in gc.get_objects():\n",
    "\t\ttry:\n",
    "\t\t\tif torch.is_tensor(obj):\n",
    "\t\t\t\tif not gpu_only or obj.is_cuda:\n",
    "\t\t\t\t\tprint(\"%s:%s%s %s\" % (type(obj).__name__, \n",
    "\t\t\t\t\t\t\t\t\t\t  \" GPU\" if obj.is_cuda else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t  \" pinned\" if obj.is_pinned else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t  pretty_size(obj.size())))\n",
    "\t\t\t\t\ttotal_size += obj.numel()\n",
    "\t\t\telif hasattr(obj, \"data\") and torch.is_tensor(obj.data):\n",
    "\t\t\t\tif not gpu_only or obj.is_cuda:\n",
    "\t\t\t\t\tprint(\"%s → %s:%s%s%s%s %s\" % (type(obj).__name__, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   type(obj.data).__name__, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   \" GPU\" if obj.is_cuda else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   \" pinned\" if obj.data.is_pinned else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   \" grad\" if obj.requires_grad else \"\", \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   \" volatile\" if obj.volatile else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   pretty_size(obj.data.size())))\n",
    "\t\t\t\t\ttotal_size += obj.data.numel()\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tpass        \n",
    "\tprint(\"Total size:\", total_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
